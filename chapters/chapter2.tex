\chapter{Slither's performance analysis}
This chapter will be dedicated to assessing Slither's performance in terms of vulnerability detection. The metrics used to determine how well security scanning tools work are: detection rate (how often a tool can correctly flag a vulnerability), analysis speed and attacks coverage (the variety of attacks that a tool can prevent).

\begin{table}[h]
\small
\begin{tabular}{cc|cccc|}
\cline{3-6}
                                                           &                         & \multicolumn{1}{c|}{Slither} & \multicolumn{1}{c|}{Securify} & \multicolumn{1}{c|}{SmartCheck} & Solhint       \\ \hline
\multicolumn{1}{|c|}{\multirow{3}{*}{Accuracy}}            & False Positive Rate     & 10.9\%                       & 25\%                          & 73.6\%                          & 91.3\%        \\
\multicolumn{1}{|c|}{}                                     & Flagged contracts       & 112                          & 8                             & 793                             & 81            \\
\multicolumn{1}{|c|}{}                                     & Detections per contract & 3.17                         & 2.12                          & 10.22                           & 2.16          \\ \hline
\multicolumn{1}{|c|}{\multirow{2}{*}{Performance}}         & Execution time(s)  & 0.79 $\pm$ 1                   & 41.4 $\pm$ 46.3  & 10.9 $\pm$ 7.14                   & 0.95 $\pm$ 0.35 \\
\multicolumn{1}{|c|}{}                                     & Time out rate           & 0\%                          & 20.4\%                        & 4\%                             & 0\%           \\ \hline
\multicolumn{1}{|c|}{Robustness}                           & Failure rate            & 0.1\%                        & 11.2\%                        & 10.22\%                         & 1.2\%         \\ \hline
\multicolumn{1}{|c|}{\multirow{2}{*}{Reentrancy examples}} & DAO                     & Yes                          & No                            & Yes                             & No            \\
\multicolumn{1}{|c|}{}                                     & Spankchain              & Yes                          & No                            & No                              & No            \\ \hline
\end{tabular}
\caption{Performance comparison between Slither, Securify, SmartCheck and Solhint. From Josselin F. et al. \cite{slither}}
\label{tab:my-table}
\end{table}

The table above covers the first two performance criteria: the detection rate and analysis speed. The experiment was done by analyzing 1000 contracts focusing only on reentrancy detectors. Slither's results are visibly better than the ones obtained by its counterparts. Firstly, it's false positive rate is far lower, at just 10.9\%, while Securify falls in the second place with 25\%. Secondly, it's average execution time is also significantly lower than those of Securify and SmartCheck. In short, Slither is by far faster, more accurate and more consistent than the other three tools. Another important aspect is the time out rate of 0\% for Slither and Solhint, which further supports Slither's consistency in the detection of reentrancy attacks. Also, while this results do not conclude Slither's attack coverage, we can see it is the only tool that managed to detect attacks similar to the ones that targeted DAO or Spankchain, which are notorious for the amount of funds stolen and its effect on people's perception towards blockchain's security.

\begin{table}[h]
\centering
\begin{tabular}{|cccccc|}
\hline
\multicolumn{1}{|c|}{Vulnerabilities} & \multicolumn{1}{c|}{Read} & \multicolumn{1}{c|}{TP} & \multicolumn{1}{c|}{TN} & \multicolumn{1}{c|}{FP} & FN \\ \hline
\multicolumn{1}{|c|}{Re-entrancy}     & 29/31                     & 28                      & 0                       & 0                       & 1  \\
\multicolumn{1}{|c|}{Access Control}  & 18/18                     & 14                      & 0                       & 0                       & 3  \\
\multicolumn{1}{|c|}{Arithmetic}      & 15/15                     & 0                       & 0                       & 5                       & 0  \\
\multicolumn{1}{|c|}{Unchecked LLC}   & 26/26                     & 26                      & 0                       & 0                       & 3  \\ \hline
Total                                 & 88                        & 68                      & 0                       & 5                       & 7  \\ \hline
\end{tabular}
\caption{Slither's coverage of security attacks. Adapted from Senan B.  \cite{staticAnalysisTest}}
\label{tab:my-table1}
\end{table}

This table shows how Slither can detect four types of vulnerabilities: Reentrancy, Access Control, Arithmetic and Unchecked LLC and covers 4 output categories: True Positive (TP), True Negative (TN), False Positive (FP) and False Negative (FN). Out of the 90 test cases given, 88 passed the reading phase, 68 had got correctly flagged as vulnerable, five ended up as False Positives and seven as False Negatives. That equates to a rate of 77.27\% for True Positive, 5.68\% for False Positive and 7.95\% for False Negative. Therefore, while in almost 6\% of cases the user is falsely lead to believe a section of his code is vulnerable, a case that has no impact on the project's security, the rate at which Slither misses a vulnerability is almost 8\%. 

\begin{table}[h]
\centering
\begin{tabular}{|c|cc|}
\hline
Vulnerabilities & Slither & SmartCheck \\ \hline
Bad Randomness  & 2.99s   & 8.9s       \\
Access Control  & 2.98s   & 10s        \\
Reentrancy      & 2.48s   & *32.2s     \\
Arithmetic      & 3.09s   & 21.16s     \\ \hline
\end{tabular}
\caption{Detection rate of Slither compared to SmartCheck, another static analysis tool. *SmartCheck registered a significantly lower detection rate for reentrancy attacks. Adapted from \cite{slitherVSsmartCheck}}
\label{tab:my-table}
\end{table}

According to the table above, Slither is by far faster than SmartCheck at detecting vulnerabilities across all four types included. Also, both tools properly detected the vulnerabilities, so the quality of Slither's detection is just as high as SmartCheck's, except for reentrancy attacks, where SmartCheck missed a significant part of the issues. In short, Slither is much faster and more reliable than SmartCheck.

Among the included attacks, there are two new types: bad randomness and arithmetic. Bad randomness \cite{badRandomness} attacks may take place when a contract generates random numbers through unsafe methods, such as using the block's timestamp as the seed for essential operations, like asset transfer. If the attacker is able to predict the seed (for example, by initiating a transaction at a certain time), they may get an undeserved advantage over honest users and could obtain more funds, depending on the attacked application.

Arithmetic attacks \cite{arithmeticAttack} are specific to smart cotracts that use versions of Solidity older than Solidity 0.8. This type of attack is done by overflowing or underflowing an variable. Overflowing a variable is done by incrementing it over its limit (for an uint8 variable, adding one to 255 will return 0). Underflowing is done similarly through decrementation. Fortunately, newer versions of Solidity throw errors in these cases and the older ones have access to the SafeMath library, so these vulnerabilities are easy to solve.

As seen in the previous paragraphs, Slither is a great tool for detecting security vulnerabilities, consistently finding issues almost regardless of their category. This high detection rate is backed up by its high speed of processing smart contracts, which is another strong point of Slither. Furthermore, unlike its competition, this tool is also able to detect optimization opportunities in smart contracts.

Smart contract optimization, while not a major security concern, used to be an important subject for Ethereum-based smart contracts developers. This was the case before The Merge, when Ethereum tranzitioned from the Proof-of-Work consensus to a Proof-of-Stake one. The Proof-of-Work model relied on validators using large amounts of electricity through mining in order to verify transactions and an inefficient smart contract on top of that would only have worsened the problem. However, the shift towards the Proof-of-Stake consensus meant that Ethereum would dramatically lower it's energy consumption by over 99.9\% on september 14th 2022 \cite{ethereumLowerElectricity}.

Now, because the energy consumption is not as threatening, optimizing a smart contract is more of a matter of reducing the risk of intruders using inefficient code as backdoors for their attacks and ensuring a fast and responsive application for its users. As far as the latest researches go, Slither \cite{slither} had been tested for detecting constant variables that were not declared accordingly. A properly declared constant variable will take no space in the storage of the contract and can be accessed with fewer instructions when needed. However, a non-constant variable that acts as a constant (it doesn't change its value under any circumstance) could unnecessarly increase the code size and the usage cost. Slither was tested on a total of 36.000 contracts and up to 56\% of them were found to have variables that acted as constants or variables that ended up not being used at all. These findings prove that Slither is able to detect basic, but useful, code optimization.

Thanks to its optimization detection and coverage of various categories of attacks, Slither is a great tool for security audits. However, it can also be used for educational purposes in blockchain related courses, where the students could run it on their projects and see its security vulnerabilities. The usage of Slither in such early stages of learning smart contract development raises awareness of the most common attacks and helps the student avoid leaving the project vulnerable in the future.

Another subject of great importance when discussing Slither, or any similar tool, are the legal aspects and the ethical considerations of using it. The first and most important matter is the fact that, while the developers of a smart contract may run Slither on their project to find and fix its vulnerabilities, intruders may do the same to find exploitable pieces of code to focus their attack on. Of course, this is mostly possible in the case of an open-source project, unless the developers are quick enough to detect and fix all the security problems before any attacker manages to exploit them. In other words, Slither may be both the guard that points out security issues and the complice that helps the attacker find the right way to exploit the contract.

Similarly, Slither can be used by regular users on open-source smart contracts to assess whether they are safe to use and may contact the developers in case they find glaring problems. In the meantime, developers should take responsability for the security of their project and conduct manual analysis of the code on top of using automated tools. In the end, security analysis tools are far from perfect and are subject to throwing false positives or negatives. As such, the developers are the only ones responsible with avoiding security attacks to the best of their abilities.